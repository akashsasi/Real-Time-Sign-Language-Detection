{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76c55c76",
   "metadata": {},
   "source": [
    "# Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3867fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a413f420",
   "metadata": {},
   "source": [
    "# Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77b35c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data for class 0\n",
      "Collecting data for class 1\n",
      "Collecting data for class 2\n",
      "Collecting data for class 3\n",
      "Collecting data for class 4\n",
      "Collecting data for class 5\n",
      "Collecting data for class 6\n",
      "Collecting data for class 7\n",
      "Collecting data for class 8\n",
      "Collecting data for class 9\n"
     ]
    }
   ],
   "source": [
    "# Define the main data directory path\n",
    "DATA_DIR = './data'\n",
    "\n",
    "# Check if the main data directory exists; if not, create it\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    os.makedirs(DATA_DIR)\n",
    "    \n",
    "# Specify the number of classes and the desired dataset size for each class\n",
    "number_of_classes = 10\n",
    "dataset_size = 200\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "for j in range(number_of_classes):\n",
    "    # Check if the directory for the current class does not exist; if not, create it\n",
    "    if not os.path.exists(os.path.join(DATA_DIR, str(j))):\n",
    "        os.makedirs(os.path.join(DATA_DIR, str(j)))\n",
    "\n",
    "    print('Collecting data for class {}'.format(j))\n",
    "\n",
    "    # infinite loop for capturing images\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        # Display a message on the frame\n",
    "        cv2.putText(frame, 'Ready? Press \"S\" :)', (100, 50), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 255, 0), 3,\n",
    "                    cv2.LINE_AA)\n",
    "        cv2.imshow('frame', frame)\n",
    "        # Break the loop if the user presses 's'\n",
    "        if cv2.waitKey(25) == ord('s'):\n",
    "            break\n",
    "\n",
    "    counter = 0\n",
    "    # Enter a loop to capture and save images\n",
    "    while counter < dataset_size:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.imshow('frame', frame)\n",
    "        cv2.waitKey(25)\n",
    "        # Save the current frame as an image in the specified directory\n",
    "        cv2.imwrite(os.path.join(DATA_DIR, str(j), '{}.jpg'.format(counter)), frame)\n",
    "        counter += 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71088bb",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "\n",
    "Extracting Features using the MediaPipe library to detect hand landmarks in images and then extracting the (x, y) coordinates of these landmarks to create a dataset for hand gesture recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3d7766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = './data'\n",
    "\n",
    "# Initialize MediaPipe Hands module\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "# Iterate over subdirectories in the main data directory\n",
    "for dir_ in os.listdir(DATA_DIR):\n",
    "    for img_path in os.listdir(os.path.join(DATA_DIR, dir_)):\n",
    "        data_aux = []\n",
    "        \n",
    "        # Read the image and convert it to RGB\n",
    "        img = cv2.imread(os.path.join(DATA_DIR, dir_, img_path))\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Process the image to detect hand landmarks\n",
    "        results = hands.process(img_rgb)\n",
    "        \n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "#                 mp_drawing.draw_landmarks(\n",
    "#                 img_rgb,\n",
    "#                 hand_landmarks,\n",
    "#                 mp_hands.HAND_CONNECTIONS,\n",
    "#                 mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "#                 mp_drawing_styles.get_default_hand_connections_style())\n",
    "                # Iterate over individual landmarks and store (x, y) coordinates\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "                    data_aux.append(x)\n",
    "                    data_aux.append(y)\n",
    "            data.append(data_aux)\n",
    "            labels.append(dir_)\n",
    "            \n",
    "\n",
    "\n",
    "#             plt.figure\n",
    "#             plt.imshow(img_rgb)\n",
    "#             plt.show()\n",
    "\n",
    "# Save the data and labels into a pickle file\n",
    "f = open('data.pickle', 'wb')\n",
    "pickle.dump({'data': data, 'labels': labels}, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612f21b5",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "# (i) Random Forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a913024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load serialized data from 'data.pickle' file\n",
    "data_dict = pickle.load(open('./data.pickle', 'rb'))\n",
    "\n",
    "# Convert data and labels to NumPy arrays\n",
    "data = np.asarray(data_dict['data'])\n",
    "labels = np.asarray(data_dict['labels'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, shuffle=True, stratify=labels)\n",
    "\n",
    "# Initialize a Random Forest Classifier\n",
    "RFmodel = RandomForestClassifier()\n",
    "\n",
    "# Train the classifier using the training data\n",
    "RFmodel.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_predictRF = RFmodel.predict(x_test)\n",
    "\n",
    "# Save the trained model to 'RFmodel.p' file using pickle\n",
    "f = open('RFmodel.p', 'wb')\n",
    "pickle.dump({'RFmodel': RFmodel}, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9f1f5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [1. 1. 1. 1. 1.]\n",
      "\n",
      "Random Forest Model Metrics:\n",
      "Accuracy: 100.0%\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "Confusion Matrix:\n",
      "[[40  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 40  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 40  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 40  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 40  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 40  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 40  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 40  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 40  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 40]]\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(RFmodel, x_train, y_train, cv=5)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "\n",
    "accuracy_rf = accuracy_score(y_test, y_predictRF)\n",
    "precision_rf = precision_score(y_test, y_predictRF, average='weighted')\n",
    "recall_rf = recall_score(y_test, y_predictRF, average='weighted')\n",
    "f1_rf = f1_score(y_test, y_predictRF, average='weighted')\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_predictRF)\n",
    "\n",
    "print(\"\\nRandom Forest Model Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_rf*100}%\")\n",
    "print(f\"Precision: {precision_rf}\")\n",
    "print(f\"Recall: {recall_rf}\")\n",
    "print(f\"F1 Score: {f1_rf}\")\n",
    "print(f\"\\nConfusion Matrix:\\n{conf_matrix_rf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55a7243",
   "metadata": {},
   "source": [
    "# (ii) KNN Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "637e7d9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize a k-Nearest Neighbors Classifier with, for example, k=3 (you can adjust k as needed)\n",
    "KNNmodel = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Train the classifier using the training data\n",
    "KNNmodel.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_predictKNN = KNNmodel.predict(x_test)\n",
    "\n",
    "# Save the trained model to 'KNNmodel.p' file using pickle\n",
    "f = open('KNNmodel.p', 'wb')\n",
    "pickle.dump({'KNNmodel': KNNmodel}, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9feb34ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Scores: [1. 1. 1. 1. 1.]\n",
      "\n",
      "KNN Model Metrics:\n",
      "Accuracy: 100.0%\n",
      "Precision: 1.0\n",
      "Recall: 1.0\n",
      "F1 Score: 1.0\n",
      "\n",
      "Confusion Matrix:\n",
      "[[40  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 40  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 40  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 40  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 40  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 40  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 40  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 40  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 40  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 40]]\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(KNNmodel, x_train, y_train, cv=5)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-Validation Scores:\", cv_scores)\n",
    "\n",
    "# Evaluate KNN model\n",
    "accuracy_knn = accuracy_score(y_test, y_predictKNN)\n",
    "precision_knn = precision_score(y_test, y_predictKNN, average='weighted')\n",
    "recall_knn = recall_score(y_test, y_predictKNN, average='weighted')\n",
    "f1_knn = f1_score(y_test, y_predictKNN, average='weighted')\n",
    "conf_matrix_knn = confusion_matrix(y_test, y_predictKNN)\n",
    "\n",
    "print(\"\\nKNN Model Metrics:\")\n",
    "print(f\"Accuracy: {accuracy_knn*100}%\")\n",
    "print(f\"Precision: {precision_knn}\")\n",
    "print(f\"Recall: {recall_knn}\")\n",
    "print(f\"F1 Score: {f1_knn}\")\n",
    "print(f\"\\nConfusion Matrix:\\n{conf_matrix_knn}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52751a2e",
   "metadata": {},
   "source": [
    "# Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f96464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 1 for Random Forest Clssifier, 2 for KNN Algorithm :- 1\n"
     ]
    }
   ],
   "source": [
    "# User choice for the machine learning model\n",
    "choice = int(input(\"Press 1 for Random Forest Clssifier, 2 for KNN Algorithm :- \"))\n",
    "\n",
    "# Load the chosen machine learning model\n",
    "if(choice == 1):\n",
    "    model_dict = pickle.load(open('./RFmodel.p', 'rb'))\n",
    "    model = model_dict['RFmodel']\n",
    "else:\n",
    "    model_dict = pickle.load(open('./KNNmodel.p', 'rb'))\n",
    "    model = model_dict['KNNmodel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "415d5590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize MediaPipe Hands module\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "hands = mp_hands.Hands(static_image_mode=True, min_detection_confidence=0.3)\n",
    "\n",
    "# Dictionary to map predicted labels to characters\n",
    "labels_dict = {\n",
    "    0: 'A', 1: 'B', 2: 'C',\n",
    "    3: 'D', 4: 'E', 5: 'F',\n",
    "    6: 'G', 7: 'H', 8: 'I',\n",
    "    9: 'J'\n",
    "}\n",
    "\n",
    "\n",
    "# Variables for response time calculation\n",
    "start_time = 0\n",
    "end_time = 0\n",
    "response_time_list = []\n",
    "\n",
    "while True:\n",
    "    \n",
    "    data_aux = []\n",
    "    ret, frame = cap.read()    \n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    results = hands.process(frame_rgb)\n",
    "    \n",
    "    # Draw landmarks and connections on the frame\n",
    "    if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                frame,\n",
    "                hand_landmarks,\n",
    "                mp_hands.HAND_CONNECTIONS,\n",
    "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                mp_drawing_styles.get_default_hand_connections_style())\n",
    "                \n",
    "            # Collect hand landmarks data for prediction    \n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                for i in range(len(hand_landmarks.landmark)):\n",
    "                    x = hand_landmarks.landmark[i].x\n",
    "                    y = hand_landmarks.landmark[i].y\n",
    "                    data_aux.append(x)\n",
    "                    data_aux.append(y)\n",
    "            \n",
    "            # Make a prediction using the loaded machine learning model\n",
    "            prediction = model.predict([np.asarray(data_aux)])\n",
    "            \n",
    "            # Map the predicted label to a character\n",
    "            predicted_character = labels_dict[int(prediction[0])]\n",
    "            \n",
    "            cv2.putText(frame, predicted_character, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 3)\n",
    "            \n",
    "            end_time = time.time()            \n",
    "                        \n",
    "            response_time = end_time - start_time\n",
    "            cv2.putText(frame, f'{response_time:.4f} sec', (frame.shape[1] - 200, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "            response_time_list.append(response_time)            \n",
    "\n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "     # Break the loop if 'q' is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27793dee",
   "metadata": {},
   "source": [
    "# Calculate Average response time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96e4d253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04748920836710418\n"
     ]
    }
   ],
   "source": [
    "avg_response_time = (sum(response_time_list) / len(response_time_list))\n",
    "\n",
    "print(avg_response_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c37e9b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
