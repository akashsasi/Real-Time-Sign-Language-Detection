# Real-Time-Sign-Language-Detection

This Project focuses on the detection of sign language gestures and converting them to meaningful text for deaf communities. Implementation of KNN and Random Forest Classifier is used in our project. The methodology here involves the collection of hand gestures and converting that into a dataset. I Actually brought up this Machine Learning Technique to provide seamless communication between deaf people and individual who is not well known at sign language. At last, I have also used performance metrics to check how good our model is predicting.

Notably, the system performs well, utilizing both the Random Forest and KNN classifiers to achieve 100% accuracy. Consistently, the system provides timely feedback in real time. The Random Forest Classifier exhibits a faster average response time of 0.02 seconds for recognizing and displaying sign gestures compared to the KNN model, which has an average response time of 0.06.

Libraries Used
1. Numpy
2. OpenCV
3. Mediapipe
4. sklearn
5. pickle
